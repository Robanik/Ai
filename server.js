import express from "express";
import fetch from "node-fetch";
import cors from "cors";

const app = express();
app.use(cors());
app.use(express.json());

const PORT = process.env.PORT || 3000;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

app.post("/chat", async (req, res) => {
  const { message } = req.body;

  try {
    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: "gpt-3.5-turbo",
        messages: [
          { role: "system", content: "–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∏ —É–º–Ω—ã–π —á–∞—Ç-–±–æ—Ç. –û—Ç–≤–µ—á–∞–π –ø–æ–Ω—è—Ç–Ω–æ –∏ —Å —é–º–æ—Ä–æ–º." },
          { role: "user", content: message }
        ],
        max_tokens: 150
      })
    });

    const data = await response.json();
    const botReply = data.choices[0].message.content.trim();
    res.json({ reply: botReply });

  } catch (error) {
    console.error(error);
    res.status(500).json({ reply: "–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ üòÖ" });
  }
});

app.listen(PORT, () => {
  console.log(`–°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω –Ω–∞ –ø–æ—Ä—Ç—É ${PORT}`);
});

const data = await response.json();
console.log("–û—Ç–≤–µ—Ç OpenAI:", data); // –õ–æ–≥–∏—Ä—É–µ–º, —á—Ç–æ —Ä–µ–∞–ª—å–Ω–æ –ø—Ä–∏—à–ª–æ

// –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ choices —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –º–∞—Å—Å–∏–≤ –Ω–µ –ø—É—Å—Ç–æ–π
if (!data.choices || data.choices.length === 0) {
  console.error("OpenAI –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –∏–ª–∏ –æ—à–∏–±–∫—É:", data);
  return res.status(500).json({ reply: "–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ üòÖ" });
}

const botReply = data.choices[0].message.content.trim();
res.json({ reply: botReply });
