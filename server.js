import express from "express";
import fetch from "node-fetch";
import cors from "cors";

const app = express();
app.use(cors());
app.use(express.json());

// –ü–æ—Ä—Ç –æ—Ç Render
const PORT = process.env.PORT || 3000;

// –ö–ª—é—á OpenAI –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è Render
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

if (!OPENAI_API_KEY) {
  console.error("–û—à–∏–±–∫–∞: –Ω–µ –∑–∞–¥–∞–Ω OPENAI_API_KEY!");
  process.exit(1); // –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å–µ—Ä–≤–µ—Ä, –µ—Å–ª–∏ –∫–ª—é—á–∞ –Ω–µ—Ç
}

app.post("/chat", async (req, res) => {
  const { message } = req.body;

  if (!message) {
    return res.status(400).json({ reply: "–°–æ–æ–±—â–µ–Ω–∏–µ –ø—É—Å—Ç–æ–µ üòÖ" });
  }

  try {
    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: "gpt-3.5-turbo",
        messages: [
          { role: "system", content: "–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∏ —É–º–Ω—ã–π —á–∞—Ç-–±–æ—Ç. –û—Ç–≤–µ—á–∞–π –ø–æ–Ω—è—Ç–Ω–æ –∏ —Å —é–º–æ—Ä–æ–º." },
          { role: "user", content: message }
        ],
        max_tokens: 150
      })
    });

    const data = await response.json();
    console.log("–û—Ç–≤–µ—Ç OpenAI:", data); // –õ–æ–≥–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏

    if (!data.choices || data.choices.length === 0) {
      console.error("OpenAI –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –∏–ª–∏ –æ—à–∏–±–∫—É:", data);
      res.status(500).json({ reply: "–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ üòÖ" });
      return;
    }

    const botReply = data.choices[0].message.content.trim();
    res.json({ reply: botReply });

  } catch (error) {
    console.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ OpenAI:", error);
    res.status(500).json({ reply: "–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ üòÖ" });
  }
});

app.listen(PORT, () => {
  console.log(`–°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω –Ω–∞ –ø–æ—Ä—Ç—É ${PORT}`);
});
